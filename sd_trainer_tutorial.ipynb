{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIfI71efNIMCEiAmgx+10l"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "お訓練の時間ですわよ"
      ],
      "metadata": {
        "id": "M25Gqh3Sf7mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "driveと連携します。\n",
        "drive直下にdatasetというディレクトリ名で画像データがいっぱいあるとします。"
      ],
      "metadata": {
        "id": "hqlF5O42f_kj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZHEePjqem-v"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "R1Tl9pGVf2zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/laksjdjf/sd-trainer"
      ],
      "metadata": {
        "id": "HhSC7ANMf7Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sd-trainer"
      ],
      "metadata": {
        "id": "15z7anFawzTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# アプデ用\n",
        "#!git pull origin main"
      ],
      "metadata": {
        "id": "BlxojvlagNkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers -r requirements.txt"
      ],
      "metadata": {
        "id": "hjcka6BFgMZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データの前処理"
      ],
      "metadata": {
        "id": "GSqBmY3kgeVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データセットがある場所や前処理用のパス、使うモデルを指定してください。"
      ],
      "metadata": {
        "id": "MjKudqgQtNDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 画像データがあるディレクトリのパスを指定してください。\n",
        "dataset_path = \"../dataset\"\n",
        "\n",
        "# 実際に訓練で使うデータセットのディレクトリパスを指定してください。\n",
        "dataset_preprocess_path = \"../dataset_preprocess/\"\n",
        "\n",
        "# モデルのパス（huggingfaceのモデル等）\n",
        "model = \"waifu-diffusion/wd-1-5-beta2\""
      ],
      "metadata": {
        "id": "EszNgeHNgPFB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aspect ratio bucketing\n",
        "\n",
        "解像度の候補(bucket)をいくつか作ってそれにあわせます。"
      ],
      "metadata": {
        "id": "Ik-4QuuMg88z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 preprocess/bucketing.py \\\n",
        "--input_dir {dataset_path} \\\n",
        "--output_dir {os.path.join(dataset_preprocess_path,\"images\")} \\\n",
        "--resolution 768 \\\n",
        "--min_length 512 \\\n",
        "--max_length 1024 \\\n",
        "--max_ratio 2 \\\n",
        "--threads 2\n",
        "\n",
        "#メタデータを親ディレクトリに移動（ちょっとわかりづらいね）\n",
        "!mv {os.path.join(dataset_preprocess_path,\"images\",\"buckets.json\")} {dataset_preprocess_path}"
      ],
      "metadata": {
        "id": "TeA6OVq6g56N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 潜在変数のキャッシュ\n",
        "\n",
        "VAEによる潜在変数への変換結果をキャッシュします。"
      ],
      "metadata": {
        "id": "VOY4fnuCiia_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess/latent.py \\\n",
        "--directory {os.path.join(dataset_preprocess_path,\"images\")} \\\n",
        "--output_path {os.path.join(dataset_preprocess_path,\"latents\")} \\\n",
        "--model {model} \\\n",
        "--batch_size 4"
      ],
      "metadata": {
        "id": "h-1oWv-Qh9e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wd14taggerによるキャプションづけ\n",
        "\n",
        "もっと高度なことしたい人は自分でやってcaptionsディレクトリに入れてください。ファイル名は画像と同じで、拡張子だけ.captionにしてください。"
      ],
      "metadata": {
        "id": "jN0TALk7mpQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#wd14-taggerを直下にダウンロードします。\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "\n",
        "DEFAULT_WD14_TAGGER_REPO = 'SmilingWolf/wd-v1-4-vit-tagger-v2'\n",
        "TAGGER_DIR = 'wd-v1-4-vit-tagger-v2'\n",
        "FILES = [\"keras_metadata.pb\", \"saved_model.pb\",\"selected_tags.csv\"]\n",
        "SUB_DIR = \"variables\"\n",
        "SUB_DIR_FILES = [\"variables.data-00000-of-00001\", \"variables.index\"]\n",
        "\n",
        "def download(path):\n",
        "    model_dir = os.path.join(path, TAGGER_DIR)\n",
        "    if not os.path.exists(model_dir):\n",
        "        print(f\"downloading wd14 tagger model from hf_hub. id: {DEFAULT_WD14_TAGGER_REPO}\")\n",
        "        for file in FILES:\n",
        "            hf_hub_download(DEFAULT_WD14_TAGGER_REPO, file, cache_dir=model_dir, force_download=True, force_filename=file)\n",
        "        for file in SUB_DIR_FILES:\n",
        "            hf_hub_download(DEFAULT_WD14_TAGGER_REPO, file, subfolder=SUB_DIR, cache_dir=os.path.join(\n",
        "                model_dir, SUB_DIR), force_download=True, force_filename=file)\n",
        "    else:\n",
        "        print(\"using existing wd14 tagger model\")\n",
        "\n",
        "download(\"./\")"
      ],
      "metadata": {
        "id": "xiXnPW_blSOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#thresholdはタグ付けの閾値で、1に近づくほどタグが正確な代わりに少なくなり、0に近づけると不正確だがタグ数は多くなります。\n",
        "\n",
        "!python preprocess/tagger.py \\\n",
        "--directory {os.path.join(dataset_preprocess_path,\"images\")} \\\n",
        "--output_path {os.path.join(dataset_preprocess_path,\"captions\")} \\\n",
        "--tagger_path {TAGGER_DIR} \\\n",
        "--make_caption \\\n",
        "--batch_size 4 \\\n",
        "--threshold 0.35"
      ],
      "metadata": {
        "id": "YgCVQEC6nOcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pfgの特徴量を設定(任意)\n",
        "\n",
        "pfgを学習したい場合は、pfgの特徴量をキャプションのところでもダウンロードしたwd14taggerで計算します。"
      ],
      "metadata": {
        "id": "noE9YYxBqInM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess/create_pfg_feature.py \\\n",
        "--directory {os.path.join(dataset_preprocess_path,\"images\")} \\\n",
        "--output_path {os.path.join(dataset_preprocess_path,\"pfg\")} \\\n",
        "--batch_size 4 \\\n",
        "--threshold 0.35"
      ],
      "metadata": {
        "id": "seuBu4wmqDUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## maskによる学習\n",
        "\n",
        "顔部分だけマスクして学習したい場合は以下を実行してマスクデータをげっとしてください。"
      ],
      "metadata": {
        "id": "uCwDAJFPq9Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/nagadomi/lbpcascade_animeface/master/lbpcascade_animeface.xml"
      ],
      "metadata": {
        "id": "mybOgm2arm6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(os.path.join(dataset_preprocess_path,\"mask\"),exist_ok=True)"
      ],
      "metadata": {
        "id": "Kwe0A6hRro8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess/create_mask.py \\\n",
        "--path {os.path.join(dataset_preprocess_path,\"images\")} \\\n",
        "--output_path {os.path.join(dataset_preprocess_path,\"mask\")}"
      ],
      "metadata": {
        "id": "5bW91-o-qtyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ControlNetの学習\n",
        "\n",
        "ControlNetを学習する際はControlNetに入力する画像が必要です。前処理はタスクごとに変わるので例はありません。基本的にはcontrolディレクトリにその画像を入れればいいわけですが、utils/dataset.py内のControlDatasetを書き換えるという手も一応あります。"
      ],
      "metadata": {
        "id": "0EJ-H5omr27e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習設定"
      ],
      "metadata": {
        "id": "mQqObcbUuB3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この訓練コードではyamlファイルで学習設定を管理していますが、colabでは編集しづらいので、元記事を参照してください。\n",
        "\n",
        "今回はmaskを使いつつLoRAを学習してみます。"
      ],
      "metadata": {
        "id": "hrPRTLSluP7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml = f'''\n",
        "model: \n",
        "    input_path: {model}\n",
        "    output_name: output\n",
        "    v2: true #今のところ使わないのだが、一応\n",
        "    v_prediction: true #SDv2(768)系のみtrue\n",
        "    \n",
        "dataset:\n",
        "    module: utils.dataset.BaseDataset\n",
        "    args:\n",
        "        metadata: \"buckets.json\"\n",
        "        path: \"{dataset_preprocess_path}\"\n",
        "        mask: true\n",
        "        pfg: false\n",
        "        control: false\n",
        "        prefix: \"anime, \"\n",
        "    loader:\n",
        "        module: torch.utils.data.DataLoader\n",
        "        collate_fn: \"identity\"\n",
        "        args:\n",
        "            num_workers: 2\n",
        "save:\n",
        "    module: utils.save.Save\n",
        "    args:\n",
        "        wandb_name: null\n",
        "        over_write: true\n",
        "        save_n_epochs: 1\n",
        "        save_n_steps: null\n",
        "        image_logs: \"image_logs\"\n",
        "        num_images: 4\n",
        "        resolution: \"640,896\"\n",
        "        prompt: null\n",
        "        negative_prompt: \"worst quality, low quality, medium quality, deleted, lowres, comic, bad anatomy,bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\"\n",
        "        seed: 4545\n",
        "        \n",
        "train:\n",
        "    train_unet: false\n",
        "    train_encoder: false\n",
        "    lr: \"1e-4\"\n",
        "    lr_scheduler: \"constant\"\n",
        "    epochs: 5\n",
        "    batch_size: 2\n",
        "    amp: \"bfloat16\"\n",
        "    gradient_checkpointing: false\n",
        "    use_xformers: true\n",
        "    seed: 4545\n",
        "\n",
        "feature:\n",
        "    minibatch_repeat: 1\n",
        "    up_only: false\n",
        "    step_range: \"0.0,1.0\"\n",
        "    test_steps: -1\n",
        "    \n",
        "optimizer:\n",
        "    module: torch.optim.AdamW\n",
        "    #args: 引数も指定できます。\n",
        "\n",
        "network:\n",
        "    module: networks.lora.LoRANetwork\n",
        "    train: true\n",
        "    resume: null\n",
        "    args:\n",
        "        rank: 16 # \"dynamic\"で動的に決定\n",
        "        conv_rank: null # 指定するとloconになる\n",
        "        module: null # \"loha\"でlohaになる\n",
        "'''\n",
        "\n",
        "with open(\"test.yaml\",\"w\") as f:\n",
        "    f.write(yaml)"
      ],
      "metadata": {
        "id": "io-jKJryzZa8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "うおおおおお学習だ学習だ\n",
        "\n",
        "モデルはtrained/の先で保存されます。\n",
        "検証画像はimage_logsに保存されます。"
      ],
      "metadata": {
        "id": "jWPzTgy2rcrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py test.yaml"
      ],
      "metadata": {
        "id": "zRapBX0Drp3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成はめんどうなのでありません。\n",
        "\n",
        "おわり"
      ],
      "metadata": {
        "id": "Jv5ulqzywNup"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iK-jFI_wSlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}