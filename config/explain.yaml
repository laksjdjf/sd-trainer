#説明用のファイルです。
model:
    input_path: "model" #学習対象のdiffusersモデル
    output_name: "output" #出力モデル（出力先はtrained/(models or networks or pfg or controlnet)になります）
    v2: true #今のところ使わないのだが、一応
    v_prediction: true #SDv2(768)系のみtrue
    
dataset:
    module: utils.dataset.BaseDataset
    args:
        metadata: "buckets.json"
        path: "dataset" #データセットのディレクトリパス
        mask: false #maskを使うかどうか
        pfg: false #pfgを使うかどうか
        control: false #controlnetを使うかどうか
        prefix: "" #全プロンプトの先頭に挿入する文字列。トリガーワードなどを指定するとよろし。
        prompt: null #全画像共通プロンプト、pfgのときに使う
        ucg: 0.0 #確率的にキャプションを空文にします。
    loader:
        module: torch.utils.data.DataLoader
        collate_fn: "identity"
        args:
            num_workers: 8 #cpuスレッド数と相談して
save:
    module: utils.save.Save
    args:
        wandb_name: "sd-trainer" #nullでwandbを使わなくなります。
        over_write: true #falseでチェックポイントを上書きせずどんどん増やしていきます。
        save_n_epochs: 1 #何エポックに一回セーブするか
        save_n_steps: null #何ステップに一回セーブするか、上の設定を無視します。
        image_logs: "image_logs" #検証画像生成先ディレクトリ
        num_images: 4 #検証画像の枚数
        resolution: "640,896" #検証画像の解像度（ControlNetの場合は無視）
        prompt: null #検証画像のプロンプト
        negative_prompt: "worst quality, low quality, medium quality, deleted, lowres, comic, bad anatomy,bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry"
        seed: 4545 #しこしこ
        
train:
    train_unet: true #UNetの学習をします。LoRAやControlNetの学習では基本的にfalseにしてください。同時に学習するなんていうへんてこなこともできますけど。
    train_encoder: false #テキストエンコーダを学習します。こちらはLoRAの場合はtrueにするとテキストエンコーダにもLoRAが適用されます。
    lr: "1e-5" #学習率
    lr_scheduler: "constant" #"cosine"でcosineになるよ#
    epochs: 10 #えぽっく
    batch_size: 16 #ばっちさいず
    amp: "bfloat16" #amp trueだとfloat16
    gradient_checkpointing: false #trueでVRAM使用量減、計算時間増
    use_xformers: true #xformersを使う
    
feature:
    minibatch_repeat: 1 #少ないデータでバッチサイズをあげるためのものだがちゃんとできてるか自信がないので非推奨
    up_only: false #up_blocksのみの学習ができます
    step_range: "0.0,1.0" #サンプリングステップを制限します。たとえば"0.0,0.5"ならノイズが少ない状態に限定で学習できたりします。
    test_steps: -1 #最大ステップ数、基本的に10とかにしてテストのために使う。
    
optimizer:
    module: torch.optim.AdamW #いろいろなoptimizerが使えます。
    #args: #引数も指定できます。
